<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>An√°lise L√©xica - Compiladores</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "An\u00e1lise L\u00e9xica";
        var mkdocs_page_input_path = "aula3.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> Compiladores
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../aula1/">Prazer, Compiladores! ü§ùüëæ</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../aula2/">Compila√ß√£o e Intera√ß√£o: Do C√≥digo ao Execut√°vel üíªüîß</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="#">An√°lise L√©xica</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#introducao">Introdu√ß√£o</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#objetivos-da-analise-lexica">Objetivos da An√°lise L√©xica</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#componentes-de-um-analisador-lexico">Componentes de um Analisador L√©xico</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#processo-de-analise-lexica">Processo de An√°lise L√©xica</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#exemplo-de-tokens">Exemplo de Tokens</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#desafio-em-python">Desafio em Python</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#desafio-implementar-um-analisador-lexico-em-python">Desafio: Implementar um Analisador L√©xico em Python</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#teste-esperado">Teste esperado</a>
    </li>
        </ul>
    </li>
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../aula4/">An√°lise Sem√¢ntica</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">Compiladores</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">An√°lise L√©xica</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="analise-lexica">An√°lise L√©xica</h1>
<h2 id="introducao">Introdu√ß√£o</h2>
<p>A an√°lise l√©xica, tamb√©m conhecida como lexing ou tokeniza√ß√£o, √© o primeiro est√°gio na compila√ß√£o de um programa. Esse processo envolve a convers√£o de uma sequ√™ncia de caracteres de entrada em uma sequ√™ncia de tokens, que s√£o unidades at√¥micas significativas do c√≥digo fonte. Esses tokens podem representar palavras-chave, identificadores, literais, operadores e outros elementos sint√°ticos.</p>
<h2 id="objetivos-da-analise-lexica">Objetivos da An√°lise L√©xica</h2>
<p>Os principais objetivos da an√°lise l√©xica incluem:</p>
<ol>
<li><strong>Simplifica√ß√£o da an√°lise sint√°tica</strong>: Convertendo a entrada em tokens, a an√°lise sint√°tica (ou parsing) torna-se mais simples e eficiente.</li>
<li><strong>Detec√ß√£o de erros l√©xicos</strong>: Identificar e relatar erros na fase inicial da compila√ß√£o.</li>
<li><strong>Remo√ß√£o de elementos irrelevantes</strong>: Eliminar espa√ßos em branco, coment√°rios e outros elementos que n√£o afetam a execu√ß√£o do c√≥digo.</li>
</ol>
<h2 id="componentes-de-um-analisador-lexico">Componentes de um Analisador L√©xico</h2>
<p>Um analisador l√©xico geralmente √© composto por:</p>
<ul>
<li><strong>Tabela de s√≠mbolos</strong>: Armazena informa√ß√µes sobre identificadores e palavras-chave encontradas no c√≥digo.</li>
<li><strong>Regras l√©xicas</strong>: Definem padr√µes para reconhecer tokens utilizando express√µes regulares.</li>
<li><strong>Aut√¥matos Finitos</strong>: Implementam as regras l√©xicas para varrer a entrada e produzir tokens.</li>
</ul>
<h2 id="processo-de-analise-lexica">Processo de An√°lise L√©xica</h2>
<ol>
<li><strong>Leitura da entrada</strong>: O c√≥digo fonte √© lido como uma sequ√™ncia de caracteres.</li>
<li><strong>Aplica√ß√£o de regras l√©xicas</strong>: Padr√µes s√£o aplicados para identificar diferentes tipos de tokens.</li>
<li><strong>Gera√ß√£o de tokens</strong>: Cada padr√£o identificado √© convertido em um token correspondente.</li>
<li><strong>Tratamento de erros</strong>: Se um padr√£o inv√°lido √© encontrado, um erro l√©xico √© reportado.</li>
</ol>
<h2 id="exemplo-de-tokens">Exemplo de Tokens</h2>
<p>Considere o seguinte trecho de c√≥digo:</p>
<pre><code class="language-python">int main() {
    int a = 10;
    int b = 20;
    int sum = a + b;
}
</code></pre>
<p>O analisador l√©xico pode gerar a seguinte sequ√™ncia de tokens:</p>
<ol>
<li><code>int</code> (palavra-chave)</li>
<li><code>main</code> (identificador)</li>
<li><code>(</code> (s√≠mbolo)</li>
<li><code>)</code> (s√≠mbolo)</li>
<li><code>{</code> (s√≠mbolo)</li>
<li><code>int</code> (palavra-chave)</li>
<li><code>a</code> (identificador)</li>
<li><code>=</code> (operador)</li>
<li><code>10</code> (literal)</li>
<li><code>;</code> (s√≠mbolo)</li>
<li><code>int</code> (palavra-chave)</li>
<li><code>b</code> (identificador)</li>
<li><code>=</code> (operador)</li>
<li><code>20</code> (literal)</li>
<li><code>;</code> (s√≠mbolo)</li>
<li><code>int</code> (palavra-chave)</li>
<li><code>sum</code> (identificador)</li>
<li><code>=</code> (operador)</li>
<li><code>a</code> (identificador)</li>
<li><code>+</code> (operador)</li>
<li><code>b</code> (identificador)</li>
<li><code>;</code> (s√≠mbolo)</li>
<li><code>}</code> (s√≠mbolo)</li>
</ol>
<h2 id="desafio-em-python">Desafio em Python</h2>
<p>Agora que voc√™ compreendeu o b√°sico sobre an√°lise l√©xica, aqui est√° um desafio para colocar em pr√°tica seus conhecimentos. </p>
<h3 id="desafio-implementar-um-analisador-lexico-em-python">Desafio: Implementar um Analisador L√©xico em Python</h3>
<p>Escreva um analisador l√©xico em Python que reconhe√ßa os seguintes tokens em uma express√£o aritm√©tica simples contendo inteiros, operadores (<code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>) e par√™nteses:</p>
<ul>
<li>Inteiros: uma sequ√™ncia de d√≠gitos.</li>
<li>Operadores: <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code></li>
<li>Par√™nteses: <code>(</code>, <code>)</code></li>
</ul>
<p>Sua tarefa √© implementar a fun√ß√£o <code>lexical_analysis</code> que recebe uma string contendo a express√£o aritm√©tica e retorna uma lista de tokens.</p>
<pre><code class="language-python">import re

def lexical_analysis(expression):
    # Definir os padr√µes para os tokens
    token_specification = [
        ('NUMBER',    r'\d+'),    # Inteiros
        ('PLUS',      r'\+'),     # Operador +
        ('MINUS',     r'-'),      # Operador -
        ('TIMES',     r'\*'),     # Operador *
        ('DIVIDE',    r'/'),      # Operador /
        ('LPAREN',    r'\('),     # Par√™ntese esquerdo
        ('RPAREN',    r'\)'),     # Par√™ntese direito
        ('SKIP',      r'[ \t]+'), # Espa√ßos em branco
        ('MISMATCH',  r'.'),      # Qualquer outro caractere
    ]

    # Compilar as express√µes regulares em um √∫nico regex
    tok_regex = '|'.join(f'(?P&lt;{pair[0]}&gt;{pair[1]})' for pair in token_specification)
    get_token = re.compile(tok_regex).match
    line = expression.strip()
    pos = 0
    tokens = []

    # Iterar sobre a string de entrada para encontrar os tokens
    while pos &lt; len(line):
        match = get_token(line, pos)
        if match is None:
            raise RuntimeError(f'Erro l√©xico em {line[pos]}')
        pos = match.end()
        token_type = match.lastgroup
        if token_type == 'NUMBER':
            value = int(match.group(token_type))
            tokens.append((token_type, value))
        elif token_type != 'SKIP':
            tokens.append((token_type, match.group(token_type)))

    return tokens

# Teste seu analisador l√©xico
expression = &quot;3 + 5 * ( 10 - 20 ) / 2&quot;
tokens = lexical_analysis(expression)
print(tokens)
</code></pre>
<h3 id="teste-esperado">Teste esperado</h3>
<p>Para a express√£o <code>"3 + 5 * ( 10 - 20 ) / 2"</code>, a sa√≠da esperada seria:</p>
<pre><code class="language-python">[('NUMBER', 3), ('PLUS', '+'), ('NUMBER', 5), ('TIMES', '*'), 
 ('LPAREN', '('), ('NUMBER', 10), ('MINUS', '-'), ('NUMBER', 20), 
 ('RPAREN', ')'), ('DIVIDE', '/'), ('NUMBER', 2)]
</code></pre>
<p>Boa sorte e divirta-se resolvendo o desafio!</p>
<h1 id="analise-sintatica">An√°lise Sint√°tica</h1>
<h2 id="introducao_1">Introdu√ß√£o</h2>
<p>A an√°lise sint√°tica, tamb√©m conhecida como parsing, √© o segundo est√°gio do processo de compila√ß√£o. Ela envolve a an√°lise da sequ√™ncia de tokens gerada pelo analisador l√©xico para construir uma estrutura hier√°rquica, como uma √°rvore de an√°lise sint√°tica (AST - Abstract Syntax Tree). Essa √°rvore representa a estrutura gramatical do c√≥digo fonte conforme definido pela gram√°tica da linguagem de programa√ß√£o.</p>
<h2 id="objetivos-da-analise-sintatica">Objetivos da An√°lise Sint√°tica</h2>
<p>Os principais objetivos da an√°lise sint√°tica incluem:</p>
<ol>
<li><strong>Verifica√ß√£o da estrutura gramatical</strong>: Garantir que a sequ√™ncia de tokens obede√ßa √†s regras gramaticais da linguagem.</li>
<li><strong>Constru√ß√£o de estruturas hier√°rquicas</strong>: Criar representa√ß√µes estruturais do c√≥digo, como √°rvores de an√°lise ou grafos.</li>
<li><strong>Detec√ß√£o de erros sint√°ticos</strong>: Identificar e relatar erros gramaticais.</li>
</ol>
<h2 id="componentes-de-um-analisador-sintatico">Componentes de um Analisador Sint√°tico</h2>
<p>Um analisador sint√°tico geralmente √© composto por:</p>
<ul>
<li><strong>Gram√°tica da linguagem</strong>: Um conjunto de regras que define a estrutura da linguagem.</li>
<li><strong>Analisador l√©xico</strong>: Um componente que fornece a sequ√™ncia de tokens.</li>
<li><strong>Algoritmo de parsing</strong>: Respons√°vel por construir a √°rvore de an√°lise a partir dos tokens.</li>
</ul>
<h2 id="processo-de-analise-sintatica">Processo de An√°lise Sint√°tica</h2>
<ol>
<li><strong>Recebimento dos tokens</strong>: A sequ√™ncia de tokens gerada pelo analisador l√©xico √© recebida.</li>
<li><strong>Aplica√ß√£o de regras gramaticais</strong>: As regras gramaticais s√£o aplicadas para construir a √°rvore de an√°lise.</li>
<li><strong>Detec√ß√£o de erros sint√°ticos</strong>: Erros s√£o detectados e reportados se a sequ√™ncia de tokens n√£o obedecer √†s regras gramaticais.</li>
</ol>
<h2 id="exemplos-de-gramaticas">Exemplos de Gram√°ticas</h2>
<p>Considere a seguinte gram√°tica para express√µes aritm√©ticas simples:</p>
<ul>
<li>Express√£o ‚Üí Termo {("+" | "-") Termo}</li>
<li>Termo ‚Üí Fator {("*" | "/") Fator}</li>
<li>Fator ‚Üí N√∫mero | "(" Express√£o ")"</li>
</ul>
<h2 id="exemplo-de-implementacao">Exemplo de Implementa√ß√£o</h2>
<p>Abaixo est√° uma implementa√ß√£o b√°sica de um analisador sint√°tico para express√µes aritm√©ticas em Python. Ele utiliza um analisador l√©xico para gerar tokens e, em seguida, constr√≥i uma √°rvore de an√°lise sint√°tica (AST).</p>
<pre><code class="language-python">import re

# Analisador L√©xico
def lexical_analysis(expression):
    token_specification = [
        ('NUMBER',    r'\d+'),    
        ('PLUS',      r'\+'),     
        ('MINUS',     r'-'),      
        ('TIMES',     r'\*'),     
        ('DIVIDE',    r'/'),      
        ('LPAREN',    r'\('),     
        ('RPAREN',    r'\)'),     
        ('SKIP',      r'[ \t]+'), 
        ('MISMATCH',  r'.'),      
    ]

    tok_regex = '|'.join(f'(?P&lt;{pair[0]}&gt;{pair[1]})' for pair in token_specification)
    get_token = re.compile(tok_regex).match
    line = expression.strip()
    pos = 0
    tokens = []

    while pos &lt; len(line):
        match = get_token(line, pos)
        if match is None:
            raise RuntimeError(f'Erro l√©xico em {line[pos]}')
        pos = match.end()
        token_type = match.lastgroup
        if token_type == 'NUMBER':
            value = int(match.group(token_type))
            tokens.append((token_type, value))
        elif token_type != 'SKIP':
            tokens.append((token_type, match.group(token_type)))

    return tokens

# Analisador Sint√°tico
class Parser:
    def __init__(self, tokens):
        self.tokens = tokens
        self.pos = 0

    def parse(self):
        return self.expression()

    def expression(self):
        node = self.term()
        while self.current_token() in ('PLUS', 'MINUS'):
            token = self.current_token()
            self.next_token()
            node = (token, node, self.term())
        return node

    def term(self):
        node = self.factor()
        while self.current_token() in ('TIMES', 'DIVIDE'):
            token = self.current_token()
            self.next_token()
            node = (token, node, self.factor())
        return node

    def factor(self):
        token = self.current_token()
        if token == 'NUMBER':
            self.next_token()
            return ('NUMBER', self.current_value())
        elif token == 'LPAREN':
            self.next_token()
            node = self.expression()
            if self.current_token() == 'RPAREN':
                self.next_token()
                return node
            else:
                raise RuntimeError(&quot;Erro: ')' esperado&quot;)
        else:
            raise RuntimeError(f&quot;Erro: Token inesperado {token}&quot;)

    def current_token(self):
        return self.tokens[self.pos][0] if self.pos &lt; len(self.tokens) else None

    def current_value(self):
        return self.tokens[self.pos - 1][1]

    def next_token(self):
        self.pos += 1

# Fun√ß√£o principal para realizar a an√°lise l√©xica e sint√°tica
def main():
    expression = &quot;3 + 5 * ( 10 - 20 ) / 2&quot;
    tokens = lexical_analysis(expression)
    print(&quot;Tokens:&quot;, tokens)

    parser = Parser(tokens)
    ast = parser.parse()
    print(&quot;AST:&quot;, ast)

# Executar a fun√ß√£o principal
if __name__ == &quot;__main__&quot;:
    main()
</code></pre>
<h2 id="desafio-em-python_1">Desafio em Python</h2>
<p>Agora que voc√™ compreendeu o b√°sico sobre an√°lise sint√°tica, aqui est√° um desafio para colocar em pr√°tica seus conhecimentos.</p>
<h3 id="desafio-implementar-um-analisador-sintatico-completo">Desafio: Implementar um Analisador Sint√°tico Completo</h3>
<p>Escreva um analisador sint√°tico que, al√©m de analisar express√µes aritm√©ticas simples, seja capaz de analisar express√µes com vari√°veis. Considere a seguinte gram√°tica estendida:</p>
<ul>
<li>Express√£o ‚Üí Termo {("+" | "-") Termo}</li>
<li>Termo ‚Üí Fator {("*" | "/") Fator}</li>
<li>Fator ‚Üí N√∫mero | Identificador | "(" Express√£o ")"</li>
<li>Identificador ‚Üí [a-zA-Z_][a-zA-Z0-9_]*</li>
</ul>
<p>Implemente a fun√ß√£o <code>parse</code> para lidar com vari√°veis e teste-a com uma express√£o que inclua vari√°veis.</p>
<pre><code class="language-python">import re

def lexical_analysis(expression):
    token_specification = [
        ('NUMBER',    r'\d+'),
        ('ID',        r'[a-zA-Z_][a-zA-Z0-9_]*'),
        ('PLUS',      r'\+'),
        ('MINUS',     r'-'),
        ('TIMES',     r'\*'),
        ('DIVIDE',    r'/'),
        ('LPAREN',    r'\('),
        ('RPAREN',    r'\)'),
        ('SKIP',      r'[ \t]+'),
        ('MISMATCH',  r'.'),
    ]

    tok_regex = '|'.join(f'(?P&lt;{pair[0]}&gt;{pair[1]})' for pair in token_specification)
    get_token = re.compile(tok_regex).match
    line = expression.strip()
    pos = 0
    tokens = []

    while pos &lt; len(line):
        match = get_token(line, pos)
        if match is None:
            raise RuntimeError(f'Erro l√©xico em {line[pos]}')
        pos = match.end()
        token_type = match.lastgroup
        if token_type in ('NUMBER', 'ID'):
            value = match.group(token_type)
            tokens.append((token_type, value))
        elif token_type != 'SKIP':
            tokens.append((token_type, match.group(token_type)))

    return tokens

class Parser:
    def __init__(self, tokens):
        self.tokens = tokens
        self.pos = 0

    def parse(self):
        return self.expression()

    def expression(self):
        node = self.term()
        while self.current_token() in ('PLUS', 'MINUS'):
            token = self.current_token()
            self.next_token()
            node = (token, node, self.term())
        return node

    def term(self):
        node = self.factor()
        while self.current_token() in ('TIMES', 'DIVIDE'):
            token = self.current_token()
            self.next_token()
            node = (token, node, self.factor())
        return node

    def factor(self):
        token = self.current_token()
        if token == 'NUMBER':
            self.next_token()
            return ('NUMBER', self.current_value())
        elif token == 'ID':
            self.next_token()
            return ('ID', self.current_value())
        elif token == 'LPAREN':
            self.next_token()
            node = self.expression()
            if self.current_token() == 'RPAREN':
                self.next_token()
                return node
            else:
                raise RuntimeError(&quot;Erro: ')' esperado&quot;)
        else:
            raise RuntimeError(f&quot;Erro: Token inesperado {token}&quot;)

    def current_token(self):
        return self.tokens[self.pos][0] if self.pos &lt; len(self.tokens) else None

    def current_value(self):
        return self.tokens[self.pos - 1][1]

    def next_token(self):
        self.pos += 1

def main():
    expression = &quot;x + 3 * ( y - 2 ) / z&quot;
    tokens = lexical_analysis(expression)
    print(&quot;Tokens:&quot;, tokens)

    parser = Parser(tokens)
    ast = parser.parse()
    print(&quot;AST:&quot;, ast)

if __name__ == &quot;__main__&quot;:
    main()
</code></pre>
<h3 id="teste-esperado_1">Teste esperado</h3>
<p>Para a express√£o <code>"x + 3 * ( y - 2 ) / z"</code>, a</p>
<p>sa√≠da esperada seria:</p>
<pre><code class="language-python">Tokens: [('ID', 'x'), ('PLUS', '+'), ('NUMBER', '3'), ('TIMES', '*'), 
         ('LPAREN', '('), ('ID', 'y'), ('MINUS', '-'), ('NUMBER', '2'), 
         ('RPAREN', ')'), ('DIVIDE', '/'), ('ID', 'z')]
AST: ('PLUS', ('ID', 'x'), ('DIVIDE', ('TIMES', ('NUMBER', '3'), ('MINUS', ('ID', 'y'), ('NUMBER', '2'))), ('ID', 'z')))
</code></pre>
<p>Boa sorte e divirta-se resolvendo o desafio!</p>
<h1 id="resumao">Resum√£o!</h1>
<h2 id="analise-de-compilacao-lexica-sintatica-e-semantica">An√°lise de Compila√ß√£o: L√©xica, Sint√°tica e Sem√¢ntica</h2>
<h2 id="introducao_2">Introdu√ß√£o</h2>
<p>O processo de compila√ß√£o de um programa pode ser dividido em v√°rias fases distintas. Cada fase tem um papel crucial na transforma√ß√£o do c√≥digo fonte em c√≥digo execut√°vel. As tr√™s principais fases s√£o a an√°lise l√©xica, a an√°lise sint√°tica e a an√°lise sem√¢ntica.</p>
<h2 id="analise-lexica_1">An√°lise L√©xica</h2>
<h3 id="objetivo">Objetivo</h3>
<p>A an√°lise l√©xica, tamb√©m conhecida como lexing ou tokeniza√ß√£o, √© a primeira etapa do processo de compila√ß√£o. Seu objetivo √© converter a sequ√™ncia de caracteres do c√≥digo fonte em uma sequ√™ncia de tokens, que s√£o as menores unidades significativas do c√≥digo.</p>
<h3 id="componentes">Componentes</h3>
<ul>
<li><strong>Tabela de s√≠mbolos</strong>: Armazena informa√ß√µes sobre identificadores e palavras-chave.</li>
<li><strong>Regras l√©xicas</strong>: Definem padr√µes para reconhecer tokens usando express√µes regulares.</li>
<li><strong>Aut√¥matos Finitos</strong>: Implementam as regras l√©xicas para varrer a entrada e produzir tokens.</li>
</ul>
<h3 id="exemplo-de-tokens_1">Exemplo de Tokens</h3>
<p>Para o c√≥digo <code>int a = 10;</code>, os tokens podem ser: <code>int</code>, <code>a</code>, <code>=</code>, <code>10</code>, <code>;</code>.</p>
<h3 id="implementacao">Implementa√ß√£o</h3>
<pre><code class="language-python">import re

def lexical_analysis(expression):
    token_specification = [
        ('NUMBER',    r'\d+'),
        ('ID',        r'[a-zA-Z_][a-zA-Z0-9_]*'),
        ('PLUS',      r'\+'),
        ('MINUS',     r'-'),
        ('TIMES',     r'\*'),
        ('DIVIDE',    r'/'),
        ('LPAREN',    r'\('),
        ('RPAREN',    r'\)'),
        ('SKIP',      r'[ \t]+'),
        ('MISMATCH',  r'.'),
    ]

    tok_regex = '|'.join(f'(?P&lt;{pair[0]}&gt;{pair[1]})' for pair in token_specification)
    get_token = re.compile(tok_regex).match
    line = expression.strip()
    pos = 0
    tokens = []

    while pos &lt; len(line):
        match = get_token(line, pos)
        if match is None:
            raise RuntimeError(f'Erro l√©xico em {line[pos]}')
        pos = match.end()
        token_type = match.lastgroup
        if token_type in ('NUMBER', 'ID'):
            value = match.group(token_type)
            tokens.append((token_type, value))
        elif token_type != 'SKIP':
            tokens.append((token_type, match.group(token_type)))

    return tokens
</code></pre>
<h2 id="analise-sintatica_1">An√°lise Sint√°tica</h2>
<h3 id="objetivo_1">Objetivo</h3>
<p>A an√°lise sint√°tica, ou parsing, √© a segunda etapa do processo de compila√ß√£o. Seu objetivo √© analisar a sequ√™ncia de tokens para construir uma estrutura hier√°rquica, como uma √°rvore de an√°lise sint√°tica (AST), que representa a estrutura gramatical do c√≥digo.</p>
<h3 id="componentes_1">Componentes</h3>
<ul>
<li><strong>Gram√°tica da linguagem</strong>: Conjunto de regras que define a estrutura da linguagem.</li>
<li><strong>Analisador l√©xico</strong>: Componente que fornece a sequ√™ncia de tokens.</li>
<li><strong>Algoritmo de parsing</strong>: Constr√≥i a √°rvore de an√°lise a partir dos tokens.</li>
</ul>
<h3 id="exemplo-de-gramatica">Exemplo de Gram√°tica</h3>
<p>Para express√µes aritm√©ticas simples:
- Express√£o ‚Üí Termo {("+" | "-") Termo}
- Termo ‚Üí Fator {("*" | "/") Fator}
- Fator ‚Üí N√∫mero | Identificador | "(" Express√£o ")"</p>
<h3 id="implementacao_1">Implementa√ß√£o</h3>
<pre><code class="language-python">class Parser:
    def __init__(self, tokens):
        self.tokens = tokens
        self.pos = 0

    def parse(self):
        return self.expression()

    def expression(self):
        node = self.term()
        while self.current_token() in ('PLUS', 'MINUS'):
            token = self.current_token()
            self.next_token()
            node = (token, node, self.term())
        return node

    def term(self):
        node = self.factor()
        while self.current_token() in ('TIMES', 'DIVIDE'):
            token = self.current_token()
            self.next_token()
            node = (token, node, self.factor())
        return node

    def factor(self):
        token = self.current_token()
        if token == 'NUMBER':
            self.next_token()
            return ('NUMBER', self.current_value())
        elif token == 'ID':
            self.next_token()
            return ('ID', self.current_value())
        elif token == 'LPAREN':
            self.next_token()
            node = self.expression()
            if self.current_token() == 'RPAREN':
                self.next_token()
                return node
            else:
                raise RuntimeError(&quot;Erro: ')' esperado&quot;)
        else:
            raise RuntimeError(f&quot;Erro: Token inesperado {token}&quot;)

    def current_token(self):
        return self.tokens[self.pos][0] if self.pos &lt; len(self.tokens) else None

    def current_value(self):
        return self.tokens[self.pos - 1][1]

    def next_token(self):
        self.pos += 1

# Fun√ß√£o principal para realizar a an√°lise l√©xica e sint√°tica
def main():
    expression = &quot;x + 3 * ( y - 2 ) / z&quot;
    tokens = lexical_analysis(expression)
    print(&quot;Tokens:&quot;, tokens)

    parser = Parser(tokens)
    ast = parser.parse()
    print(&quot;AST:&quot;, ast)

if __name__ == &quot;__main__&quot;:
    main()
</code></pre>
<h2 id="analise-semantica">An√°lise Sem√¢ntica</h2>
<h3 id="objetivo_2">Objetivo</h3>
<p>A an√°lise sem√¢ntica √© a terceira etapa do processo de compila√ß√£o. Seu objetivo √© verificar a corre√ß√£o sem√¢ntica do programa, assegurando que ele faz sentido dentro do contexto da linguagem. Isso inclui verifica√ß√£o de tipos, escopo de vari√°veis e outras regras sem√¢nticas.</p>
<h3 id="componentes_2">Componentes</h3>
<ul>
<li><strong>Tabela de s√≠mbolos</strong>: Armazena informa√ß√µes sobre identificadores, seus tipos e escopos.</li>
<li><strong>Regras sem√¢nticas</strong>: Definem as verifica√ß√µes necess√°rias para garantir a corre√ß√£o sem√¢ntica do c√≥digo.</li>
</ul>
<h3 id="processo">Processo</h3>
<ol>
<li><strong>Verifica√ß√£o de tipos</strong>: Assegurar que as opera√ß√µes s√£o realizadas entre tipos compat√≠veis.</li>
<li><strong>Resolu√ß√£o de identificadores</strong>: Garantir que todas as vari√°veis e fun√ß√µes est√£o declaradas antes de serem usadas.</li>
<li><strong>An√°lise de escopo</strong>: Verificar que as vari√°veis est√£o acess√≠veis apenas dentro do seu escopo.</li>
</ol>
<h3 id="exemplo-de-verificacao-de-tipos">Exemplo de Verifica√ß√£o de Tipos</h3>
<p>Para a express√£o <code>x + 3</code>, onde <code>x</code> √© uma vari√°vel do tipo <code>int</code>:</p>
<pre><code class="language-python">class SemanticAnalyzer:
    def __init__(self, ast, symbol_table):
        self.ast = ast
        self.symbol_table = symbol_table

    def analyze(self):
        return self._analyze_node(self.ast)

    def _analyze_node(self, node):
        if isinstance(node, tuple):
            op = node[0]
            left = self._analyze_node(node[1])
            right = self._analyze_node(node[2])
            if op in ('PLUS', 'MINUS', 'TIMES', 'DIVIDE'):
                if left != 'int' or right != 'int':
                    raise RuntimeError(f&quot;Erro sem√¢ntico: opera√ß√£o {op} inv√°lida entre {left} e {right}&quot;)
                return 'int'
        elif node[0] == 'NUMBER':
            return 'int'
        elif node[0] == 'ID':
            identifier = node[1]
            if identifier not in self.symbol_table:
                raise RuntimeError(f&quot;Erro sem√¢ntico: vari√°vel {identifier} n√£o declarada&quot;)
            return self.symbol_table[identifier]
        else:
            raise RuntimeError(f&quot;Erro sem√¢ntico: n√≥ inv√°lido {node}&quot;)

# Fun√ß√£o principal para realizar a an√°lise sem√¢ntica
def main():
    expression = &quot;x + 3 * ( y - 2 ) / z&quot;
    tokens = lexical_analysis(expression)
    print(&quot;Tokens:&quot;, tokens)

    parser = Parser(tokens)
    ast = parser.parse()
    print(&quot;AST:&quot;, ast)

    symbol_table = {'x': 'int', 'y': 'int', 'z': 'int'}
    analyzer = SemanticAnalyzer(ast, symbol_table)
    analyzer.analyze()
    print(&quot;An√°lise sem√¢ntica conclu√≠da com sucesso&quot;)

if __name__ == &quot;__main__&quot;:
    main()
</code></pre>
<h2 id="conclusao">Conclus√£o</h2>
<p>A an√°lise l√©xica, sint√°tica e sem√¢ntica s√£o etapas fundamentais do processo de compila√ß√£o, cada uma desempenhando um papel crucial na transforma√ß√£o do c√≥digo fonte em um programa execut√°vel. A an√°lise l√©xica converte o c√≥digo em tokens, a an√°lise sint√°tica constr√≥i a estrutura gramatical e a an√°lise sem√¢ntica verifica a corre√ß√£o contextual do programa. Compreender essas etapas √© essencial para o desenvolvimento de compiladores e int√©rpretes eficientes.</p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../aula2/" class="btn btn-neutral float-left" title="Compila√ß√£o e Intera√ß√£o: Do C√≥digo ao Execut√°vel üíªüîß"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../aula4/" class="btn btn-neutral float-right" title="An√°lise Sem√¢ntica">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../aula2/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../aula4/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
